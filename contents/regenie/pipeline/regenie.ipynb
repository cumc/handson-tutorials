{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beneficial-liver",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# GWAS analysis with GLMM models using Regenie\n",
    "\n",
    "This notebook implements pipelines for analyzing binary and quantitative traits association using REGENIE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "embedded-official",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run regenie.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  regenie_qc\n",
      "  regenie\n",
      "  regenie_burden\n",
      "  regenie_vc\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd VAL (as path, required)\n",
      "                        the output directory for generated files\n",
      "  --sampleFile . (as path)\n",
      "                        Path to sample file\n",
      "  --bfile VAL (as path, required)\n",
      "                        Genotype files in plink binary this is used for\n",
      "                        computing the GRM\n",
      "  --genoFile  paths('.')\n",
      "\n",
      "                        Path to bgen or bed files\n",
      "  --phenoFile VAL (as path, required)\n",
      "                        Phenotype file\n",
      "  --phenoCol VAL VAL ... (as type, required)\n",
      "                        Phenotype to be analyzed (specify the column name)\n",
      "  --covarFile . (as path)\n",
      "                        Covariate file path. Will use phenoFile if empty\n",
      "  --formatFile . (as path)\n",
      "                        Summary statisticss format file path used for unifying\n",
      "                        output column names. Will not unify names if empty\n",
      "  --covarCol  (as list)\n",
      "                        Qualitative covariates to be used in the analysis\n",
      "  --qCovarCol  (as list)\n",
      "                        Quantitative covariates to be used in the analysis\n",
      "  --numThreads 2 (as int)\n",
      "                        Specific number of threads to use\n",
      "  --bgenMinMAF 0.001 (as float)\n",
      "                        Minimum MAF to be used\n",
      "  --bgenMinINFO 0.8 (as float)\n",
      "                        Mimimum info score to be used\n",
      "  --chrList  (as list)\n",
      "                        Comma separated list of chromosomes to test in step 2\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --container ''\n",
      "                        Container to use\n",
      "\n",
      "Sections\n",
      "  regenie_qc:           Select the SNPs and samples to be used based on maf,\n",
      "                        geno, hwe and mind options\n",
      "    Workflow Options:\n",
      "      --maf-filter 0.0 (as float)\n",
      "      --geno-filter 0.0 (as float)\n",
      "      --hwe-filter 0.0 (as float)\n",
      "      --mind-filter 0.0 (as float)\n",
      "  regenie_1, regenie_burden_1, regenie_vc_1: Run REGENIE step 1: fitting the\n",
      "                        null\n",
      "    Workflow Options:\n",
      "      --bsize 400 (as int)\n",
      "                        Size of the genotype blocks to be used\n",
      "      --lowmem-dir  cwd\n",
      "\n",
      "                        Path to temporarily store block predictions\n",
      "      --trait bt\n",
      "                        Specify that traits are binary with\n",
      "                        0=control,1=case,NA=missing (default is quantitative)\n",
      "  regenie_2:            Run REGENIE step 2: association analysis\n",
      "    Workflow Options:\n",
      "      --bsize 400 (as int)\n",
      "                        Size of the genotype blocks to be used\n",
      "      --minMAC VAL (as int, required)\n",
      "                        Mimimum allele count to be used\n",
      "      --trait bt\n",
      "  regenie_burden_2, regenie_vc_2: Run regenie for rare variant aggregate tests\n",
      "    Workflow Options:\n",
      "      --trait bt\n",
      "                        Specify that traits are binary with\n",
      "                        0=control,1=case,NA=missing (default is quantitative)\n",
      "      --bsize 400 (as int)\n",
      "                        Size of the genotype blocks to be used\n",
      "      --anno-file VAL (as path, required)\n",
      "                        Annotation file format: variantID, gene and functional\n",
      "                        annotation (space/tab delimited)\n",
      "      --set-list VAL (as path, required)\n",
      "                        This file lists variants within each set/gene to use\n",
      "                        when building masks. Format: set/gene name, chromosome,\n",
      "                        physical pos set/gene, then by a comma-separated list of\n",
      "                        variants included in the set/gene.\n",
      "      --keep-gene . (as path)\n",
      "                        Select specific genes/sets to test\n",
      "      --aaf-file . (as path)\n",
      "                        Allele frequency file. format: variantId, alternative\n",
      "                        allele frequency\n",
      "      --mask-file . (as path)\n",
      "                        Select the annotations to be used in the mask file.\n",
      "                        format: mask# annotation type\n",
      "      --aaf-bins 0.001 (as list)\n",
      "                        Select the upper MAF to generate masks\n",
      "      --vc-tests skat skato skato-acat acatv acato acato-full (as list)\n",
      "                        Specify the type of test to use\n",
      "      --vc-maxAAF 0.001 (as float)\n",
      "                        Specify if you would like to only include variants whose\n",
      "                        AAF is below a given threshold\n",
      "      --vc-MACthr 10 (as int)\n",
      "                        Specify the MAc of variants to be collapsed into a\n",
      "                        burden mask which is then included in the tests instead\n",
      "                        of the individual variants.\n",
      "      --build-mask max\n",
      "                        The way in which the alternative alleles are counted\n",
      "      --minMAC VAL (as int, required)\n",
      "                        Mimimum allele count to be used\n",
      "  regenie_burden_3, regenie_vc_3:\n",
      "    Workflow Options:\n",
      "      --mask-file . (as path)\n",
      "                        Select the annotations to be used in the mask file.\n",
      "                        format: mask# annotation type\n",
      "      --aaf-bins 0.001 (as list)\n",
      "                        Select the upper MAF to generate masks\n",
      "  regenie_3, regenie_burden_4, regenie_vc_4: Merge results and log files\n",
      "    Workflow Options:\n",
      "      --[no-]reverse-log-p (default to False)\n",
      "  regenie_burden_5:     Separate the mask and MAF bins and remove the single\n",
      "                        variant genes\n",
      "    Workflow Options:\n",
      "      --k 10 (as int)\n",
      "                        Top k genes to be annotated\n",
      "      --plim 2.5e-06 (as float)\n",
      "                        P value limitation for annotation\n",
      "      --genelist ''\n",
      "                        A given list of gene for annotation\n",
      "      --mask-file . (as path)\n",
      "                        Select the annotations to be used in the mask file.\n",
      "                        format: mask# annotation type\n",
      "      --aaf-bins 0.001 (as list)\n",
      "                        Select the upper MAF to generate masks\n",
      "  regenie_vc_5:         Separate the mask and MAF bins and remove the single\n",
      "                        variant genes\n",
      "    Workflow Options:\n",
      "      --k 10 (as int)\n",
      "                        Top k genes to be annotated\n",
      "      --plim 2.5e-06 (as float)\n",
      "                        P value limitation for annotation\n",
      "      --genelist ''\n",
      "                        A given list of gene for annotation\n",
      "      --mask-file . (as path)\n",
      "                        Select the annotations to be used in the mask file.\n",
      "                        format: mask# annotation type\n",
      "      --aaf-bins 0.001 (as list)\n",
      "                        Select the upper MAF to generate masks\n",
      "  regenie_4:            Manhattan and QQ plots using `qqman`\n",
      "    Workflow Options:\n",
      "      --bp POS\n",
      "                        Column name for BP\n",
      "      --pval P\n",
      "                        Column name for p-value\n",
      "      --snp SNP\n",
      "                        Column name for SNP\n",
      "      --ylim 0 (as int)\n",
      "                        ylim set to 0 to use maximum -log10(p) in data\n",
      "  regenie_vc_6:         Manhattan and QQ plots using `qqman`\n",
      "    Workflow Options:\n",
      "      --bp POS\n",
      "                        Column name for BP\n",
      "      --pval P\n",
      "                        Column name for p-value\n",
      "      --snp SNP\n",
      "                        Column name for genes\n",
      "      --ylim 0 (as int)\n",
      "                        ylim set to 0 to use maximum -log10(p) in data\n",
      "      --aaf-bins 0.001 (as list)\n",
      "                        Select the upper MAF to generate masks\n",
      "      --vc-tests-reg ADD-SKAT ADD-SKATO (as list)\n",
      "                        The vc_tests performed\n",
      "      --mask-file . (as path)\n",
      "                        Select the annotations to be used in the mask file.\n",
      "                        format: mask# annotation_type\n",
      "  regenie_burden_6:     Manhattan and QQ plots using `qqman`\n",
      "    Workflow Options:\n",
      "      --bp POS\n",
      "                        Column name for BP\n",
      "      --pval P\n",
      "                        Column name for p-value\n",
      "      --snp SNP\n",
      "                        Column name for genes\n",
      "      --ylim 0 (as int)\n",
      "                        ylim set to 0 to use maximum -log10(p) in data\n",
      "      --aaf-bins 0.001 (as list)\n",
      "                        Select the upper MAF to generate masks\n",
      "      --mask-file . (as path)\n",
      "                        Select the annotations to be used in the mask file.\n",
      "                        format: mask# annotation_type\n"
     ]
    }
   ],
   "source": [
    "sos run regenie.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-kenya",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# the output directory for generated files\n",
    "parameter: cwd = path\n",
    "# Path to sample file\n",
    "parameter: sampleFile = path('.')\n",
    "# Genotype files in plink binary this is used for computing the GRM\n",
    "parameter: bfile = path\n",
    "# Path to bgen or bed files \n",
    "parameter: genoFile = paths('.')\n",
    "# Phenotype file \n",
    "parameter: phenoFile = path\n",
    "# Phenotype to be analyzed (specify the column name)\n",
    "parameter: phenoCol = list\n",
    "# Covariate file path. Will use phenoFile if empty\n",
    "parameter: covarFile = path('.')\n",
    "# Summary statisticss format file path used for unifying output column names. Will not unify names if empty\n",
    "parameter: formatFile = path('.')\n",
    "# Qualitative covariates to be used in the analysis\n",
    "parameter: covarCol = []\n",
    "# Quantitative covariates to be used in the analysis\n",
    "parameter: qCovarCol = []\n",
    "# Specific number of threads to use\n",
    "parameter: numThreads = 2\n",
    "# Minimum MAF to be used\n",
    "parameter: bgenMinMAF = 0.001\n",
    "# Mimimum info score to be used\n",
    "parameter: bgenMinINFO = 0.8\n",
    "#Comma separated list of chromosomes to test in step 2\n",
    "parameter: chrList = []\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Container to use\n",
    "parameter: container = ''\n",
    "if not covarFile.is_file():\n",
    "    covarFile = phenoFile\n",
    "cwd = path(f\"{cwd:a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-station",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Select the SNPs and samples to be used based on maf, geno, hwe and mind options\n",
    "[regenie_qc]\n",
    "parameter: maf_filter = 0.0\n",
    "parameter: geno_filter = 0.0\n",
    "parameter: hwe_filter = 0.0\n",
    "parameter: mind_filter = 0.0\n",
    "input: bfile\n",
    "output: f'{cwd}/cache/{bfile:bn}.qc_pass.id', f'{cwd}/cache/{bfile:bn}.qc_pass.snplist' \n",
    "task: trunk_workers = 1, walltime = '10h', mem = '30G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container= container, expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout' \n",
    "    plink2 \\\n",
    "      --bfile ${bfile:n} --mac 1 \\\n",
    "      ${('--maf %s' % maf_filter) if maf_filter > 0 else ''} ${('--geno %s' % geno_filter) if geno_filter > 0 else ''} ${('--hwe %s' % hwe_filter) if hwe_filter > 0 else ''} ${('--mind %s' % mind_filter) if mind_filter > 0 else ''} \\\n",
    "      --write-snplist --write-samples --no-id-header \\\n",
    "      --threads ${numThreads} \\\n",
    "      --out ${_output[0]:n} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-hospital",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step 1. Fitting the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-estate",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run REGENIE step 1: fitting the null\n",
    "[regenie_1,regenie_burden_1,regenie_vc_1]\n",
    "# Size of the genotype blocks to be used \n",
    "parameter: bsize = 400\n",
    "# Path to temporarily store block predictions\n",
    "parameter: lowmem_dir = cwd\n",
    "# Specify that traits are binary with 0=control,1=case,NA=missing (default is quantitative)\n",
    "parameter: trait = 'bt'\n",
    "# extract and prepare phenotype & covariate files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dat = pd.read_csv(phenoFile, header=0, sep=r'\\s+', dtype=str)\n",
    "dat = dat.replace(to_replace =np.nan, value =\"NA\")\n",
    "if len(phenoCol) > 0:    \n",
    "    dat.to_csv(f\"{cwd}/{phenoFile:bn}.regenie_phenotype\", sep='\\t', index=False, columns = ['FID', 'IID'] + phenoCol)\n",
    "dat = pd.read_csv(covarFile, header=0, sep=r'\\s+', dtype=str)\n",
    "if len(covarCol) > 0 or len(qCovarCol) > 0:\n",
    "    dat = dat.dropna(subset=covarCol)\n",
    "    dat = dat.dropna(subset=qCovarCol)\n",
    "    dat.replace(to_replace =np.nan, value =\"NA\")\n",
    "    dat1 = pd.DataFrame(dat, columns = ['FID','IID'] + covarCol)\n",
    "    #dat1 = dat1.astype(int)\n",
    "    dat2 = pd.DataFrame(dat, columns = ['IID'] + qCovarCol)\n",
    "    merged_left = pd.merge(left=dat1, right=dat2, how='left', left_on='IID', right_on='IID')\n",
    "    merged_left.to_csv(f\"{cwd}/{phenoFile:bn}.regenie_covar\", sep=' ', index=False)\n",
    "depends: f'{cwd}/cache/{bfile:bn}.qc_pass.snplist', f'{cwd}/cache/{bfile:bn}.qc_pass.id'\n",
    "input: geno = bfile, pheno = f\"{cwd}/{phenoFile:bn}.regenie_phenotype\", covar = f\"{cwd}/{phenoFile:bn}.regenie_covar\", qc = output_from(\"regenie_qc\")\n",
    "output: f'{cwd}/{phenoFile:bn}_' + \"_\".join([x for x in phenoCol]) + '.regenie_pred.list'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h', mem = '15G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container= container, expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    regenie \\\n",
    "      --step 1 \\\n",
    "      --bed ${_input[\"geno\"]:n} \\\n",
    "      --phenoFile ${_input[\"pheno\"]} \\\n",
    "      --covarFile ${_input[\"covar\"]} \\\n",
    "      --keep ${_input[\"qc\"][0]} \\\n",
    "      --extract ${_input[\"qc\"][1]} \\\n",
    "      ${('--' + trait) if trait in ['bt'] else ''} \\\n",
    "      --bsize ${bsize} \\\n",
    "      --lowmem --lowmem-prefix ${lowmem_dir:a}/${_output:bn} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --out ${_output:nn}.regenie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-collection",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step 2: association analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-saint",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run REGENIE step 2: association analysis\n",
    "[regenie_2]\n",
    "# Size of the genotype blocks to be used \n",
    "parameter: bsize = 400\n",
    "# Mimimum allele count to be used\n",
    "parameter: minMAC = int\n",
    "parameter: trait = 'bt'\n",
    "input: genoFile, group_by = 1, group_with = dict(info=[(path(f'{cwd}/{phenoFile:bn}_' + \"_\".join([x for x in phenoCol]) + '.regenie_pred.list'))] * len(genoFile))\n",
    "input_options = f\"--bgen {_input} --sample {sampleFile}\" if _input.suffix == \".bgen\" else f\"--bed {_input:n}\"\n",
    "output: [f'{cwd}/{_input:bn}_'+ str(phenoCol[i]) + '.regenie.gz' for i in range(len(phenoCol))]\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h', mem = '15G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container= container, expand = \"${ }\", stderr = f'{cwd}/cache/{_input:bn}.stderr', stdout = f'{cwd}/cache/{_input:bn}.stdout'\n",
    "    set -e\n",
    "    regenie \\\n",
    "     --step 2 \\\n",
    "     ${input_options} \\\n",
    "     --phenoFile ${cwd}/${phenoFile:bn}.regenie_phenotype \\\n",
    "     --covarFile ${cwd}/${covarFile:bn}.regenie_covar \\\n",
    "     --phenoColList ${','.join(phenoCol)} \\\n",
    "     ${('--' + trait) if trait in ['bt'] else ''} \\\n",
    "     ${'--chrList ' + ','.join(['%s' % x for x in chrList if x is not None])} \\\n",
    "     --firth \\\n",
    "     --approx \\\n",
    "     --pred ${_input.info} \\\n",
    "     --bsize ${bsize} \\\n",
    "     --minMAC ${minMAC} \\\n",
    "     --minINFO ${bgenMinINFO}\\\n",
    "     --threads ${numThreads} \\\n",
    "     --out ${cwd}/${_input:bn} && \\\n",
    "     gzip -f --best ${_output:n}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-honduras",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Regenie burden test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-hospital",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run regenie for rare variant aggregate tests\n",
    "[regenie_burden_2,regenie_vc_2]\n",
    "# Specify that traits are binary with 0=control,1=case,NA=missing (default is quantitative)\n",
    "parameter: trait = 'bt'\n",
    "# Size of the genotype blocks to be used \n",
    "parameter: bsize = 400\n",
    "# Annotation file format: variantID, gene and functional annotation (space/tab delimited)\n",
    "parameter: anno_file = path\n",
    "# This file lists variants within each set/gene to use when building masks. Format: set/gene name, chromosome, physical pos set/gene, then by a comma-separated list of variants included in the set/gene.\n",
    "parameter: set_list = path\n",
    "# Select specific genes/sets to test\n",
    "parameter: keep_gene = path(\".\")\n",
    "# Allele frequency file. format: variantId, alternative allele frequency\n",
    "parameter: aaf_file = path(\".\")\n",
    "# Select the annotations to be used in the mask file. format: mask# annotation type\n",
    "parameter: mask_file = path(\".\")\n",
    "# Select the upper MAF to generate masks\n",
    "parameter: aaf_bins =[0.001]\n",
    "# Specify the type of test to use\n",
    "parameter: vc_tests =['skat','skato','skato-acat','acatv','acato','acato-full']\n",
    "# Specify if you would like to only include variants whose AAF is below a given threshold\n",
    "parameter: vc_maxAAF = 0.001\n",
    "# Specify the MAc of variants to be collapsed into a burden mask which is then included in the tests instead of the individual variants.\n",
    "parameter: vc_MACthr = 10 ##10 is the default\n",
    "# The way in which the alternative alleles are counted\n",
    "parameter: build_mask = 'max'\n",
    "# Mimimum allele count to be used\n",
    "parameter: minMAC = int\n",
    "input: genoFile, group_by = 1, group_with = dict(info=[(path(f'{cwd}/{phenoFile:bn}_' + \"_\".join([x for x in phenoCol]) + '.regenie_pred.list'))] * len(genoFile))\n",
    "input_options = f\"--bgen {_input} --sample {sampleFile}\" if _input.suffix == \".bgen\" else f\"--bed {_input:n}\"\n",
    "output: [f'{cwd}/{_input:bn}_rarevariant_'+ str(phenoCol[i]) + '.regenie.gz' for i in range(len(phenoCol))]\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '15G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:container= container, expand = \"${ }\", stderr = f'{cwd}/{_input:bn}.stderr', stdout = f'{cwd}/{_input:bn}.stdout'\n",
    "    set -e\n",
    "    regenie \\\n",
    "      --step 2 \\\n",
    "      ${input_options} \\\n",
    "      --phenoFile ${cwd}/${phenoFile:bn}.regenie_phenotype \\\n",
    "      --covarFile ${cwd}/${covarFile:bn}.regenie_covar \\\n",
    "      --phenoColList ${','.join(phenoCol)} \\\n",
    "      ${('--' + trait) if trait in ['bt'] else ''} \\\n",
    "      ${'--chrList ' + ','.join(['%s' % x for x in chrList if x is not None])} \\\n",
    "      ${(\"--extract-sets \" + str(keep_gene)) if keep_gene.is_file() else \"\"} \\\n",
    "      --firth --approx \\\n",
    "      --pred ${_input.info} \\\n",
    "      --set-list ${set_list} \\\n",
    "      --anno-file ${anno_file} \\\n",
    "      --mask-def ${mask_file} \\\n",
    "      --aaf-bins ${\",\".join([str(x) for x in aaf_bins])}\\\n",
    "      ${('--build-mask ' + build_mask) if build_mask in ['max','sum','comphet'] else ''} \\\n",
    "      ${('--aaf-file ' + str(aaf_file)) if aaf_file.is_file() else \"\"}\\\n",
    "      ${'--vc-tests ' + ','.join(['%s' % x for x in vc_tests if x is not None])} \\\n",
    "      ${('--vc-maxAAF ' + str(vc_maxAAF)) if vc_tests is not None else ''} \\\n",
    "      ${('--vc-MACthr ' + str(vc_MACthr)) if vc_tests is not None else ''} \\\n",
    "      --singleton-carrier \\\n",
    "      --write-mask-snplist \\\n",
    "      --write-mask \\\n",
    "      --minMAC ${minMAC} \\\n",
    "      --bsize ${bsize} \\\n",
    "      --check-burden-files \\\n",
    "      --out  ${cwd}/${_input:bn}_rarevariant && \\\n",
    "      gzip -f --best ${_output:n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-migration",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[regenie_burden_3,regenie_vc_3]\n",
    "# Select the annotations to be used in the mask file. format: mask# annotation type\n",
    "parameter: mask_file = path(\".\")\n",
    "# Select the upper MAF to generate masks\n",
    "parameter: aaf_bins =[0.001]\n",
    "aaf_bins = ['singleton'] + aaf_bins\n",
    "f = open(mask_file, \"r\")\n",
    "masks = [i.split(\" \")[0] for i in f.readlines()]\n",
    "output: [f'{cwd}/cache/{_input:bn}_'+ str(phenoCol[i]) + \"_\" + str(masks[j]) + \".\" + str(aaf_bins[k]) + '.regenie.gz' for i in range(len(phenoCol)) for j in range(len(masks)) for k in range(len(aaf_bins))] \n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h', mem = '15G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "python: container= container, expand = \"${ }\", stderr = f'{cwd}/cache/{_input:bn}.stderr', stdout = f'{cwd}/cache/{_input:bn}.stdout'\n",
    "    import pandas as pd \n",
    "\n",
    "    if len(${phenoCol}) == 1:\n",
    "        _input = [${_input:r}]\n",
    "    else:\n",
    "        _input = [f'{i}' for i in \"${_input}\".split(\" \")]\n",
    "\n",
    "    allele_combos = [str(m) + \".\" + str(a) for m in ${masks} for a in ${aaf_bins}]\n",
    "    for i, phen in enumerate(${phenoCol}):\n",
    "        f = pd.read_csv(_input[i], compression='gzip', header=0, sep=r'\\s+', quotechar='\"', comment='#')\n",
    "        f= f.fillna('NA')\n",
    "        dfs = dict()\n",
    "        for each in allele_combos:\n",
    "            dfs[each] = f[f[\"ALLELE1\"] == each]\n",
    "\n",
    "        for df in dfs.keys():\n",
    "            dfs[df].to_csv(f'${cwd}/cache/${_input:bn}_{phen}'+ \"_\" + df + '.regenie.gz', sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-expense",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Merge results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-people",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Merge results and log files\n",
    "[regenie_3,regenie_burden_4,regenie_vc_4]\n",
    "parameter:reverse_log_p = False\n",
    "depends: formatFile\n",
    "input: group_by = lambda x: [x[i::len(phenoCol)] for i in range(len(phenoCol))], group_with='phenoCol'\n",
    "output: f'{cwd}/{phenoFile:bn}_{_phenoCol}.{step_name.rsplit(\"_\",1)[0]}.snp_stats.gz',\n",
    "        f'{cwd}/{phenoFile:bn}_{_phenoCol}.{step_name.rsplit(\"_\",1)[0]}.snp_counts.txt'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '1h', mem = '36G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "python: container= container, expand ='${ }'\n",
    "    import gzip\n",
    "    import pandas as pd\n",
    "\n",
    "    # Check if formatFile exists\n",
    "    if not ${formatFile.is_file()} and ${reverse_log_p}:\n",
    "        raise ValueError(\"formatFile is missing, but reverse_log_p is set to True.\")\n",
    "\n",
    "    if ${formatFile.is_file()}:\n",
    "        output = '${_output[0]:n}' + '_original_columns' + '${_output[0]:x}'\n",
    "    else:\n",
    "        output = '${_output[0]}'\n",
    "   \n",
    "\n",
    "    data = pd.concat([pd.read_csv(f, compression='gzip', header=0, sep=r'\\s+', quotechar='\"', comment='#') for f in [${_input:r,}]], ignore_index=True)\n",
    "    data=data.fillna('NA')\n",
    "    data.to_csv(output, compression='gzip', sep='\\t', header = True, index = False)\n",
    "    # unify output format\n",
    "    if ${formatFile.is_file()} or ${reverse_log_p}:\n",
    "        sumstats = pd.read_csv(output, compression='gzip', header=0, sep=r'\\s+', quotechar='\"')  \n",
    "        if ${formatFile.is_file()}:\n",
    "            import yaml\n",
    "            config = yaml.safe_load(open(${formatFile:r}, 'r'))\n",
    "        try:\n",
    "            sumstats = sumstats.loc[:,list(config.values())]\n",
    "        except:\n",
    "            raise ValueError(f'According to ${formatFile}, input summary statistics should have the following columns: {list(config.values())}.')\n",
    "        sumstats.columns = list(config.keys())\n",
    "        if ${reverse_log_p}:\n",
    "            sumstats['P'] = sumstats['P'].apply(lambda row: 10**-row)\n",
    "        sumstats.to_csv(${_output[0]:r}, compression='gzip', sep='\\t', header = True, index = False)        \n",
    "\n",
    "bash: container= container, expand=\"$( )\"\n",
    "    # count result SNPs\n",
    "    for f in $(_input); do echo \"$f: `zcat $f | wc -l`\"; done > $(_output[1])\n",
    "    # merge stderr and stdout files\n",
    "    for f in $(_input); do \n",
    "        for ext in stderr stdout log; do\n",
    "            echo \"$f $ext:\"\n",
    "            cat ${f%.gz}.$ext 2>/dev/null || true\n",
    "            rm -f ${f%.gz}.$ext \n",
    "        done\n",
    "    done > $(_output[0]:n).log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-passage",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Separate the mask and MAF bins and remove the single variant genes\n",
    "[regenie_burden_5]\n",
    "# Top k genes to be annotated\n",
    "parameter: k = 10\n",
    "# P value limitation for annotation\n",
    "parameter: plim = 2.5E-6\n",
    "# A given list of gene for annotation\n",
    "parameter: genelist = \"\"\n",
    "# Select the annotations to be used in the mask file. format: mask# annotation type\n",
    "parameter: mask_file = path(\".\")\n",
    "# Select the upper MAF to generate masks\n",
    "parameter: aaf_bins = [0.001]\n",
    "f = open(mask_file, \"r\")\n",
    "masks = [i.split(\" \")[0] for i in f.readlines()]\n",
    "bins=[str(phenoCol[i]) + f'.{step_name.rsplit(\"_\",1)[0]}.' + str(masks[j]) + \".\" + str(aaf_bins[k]) for i in range(len(phenoCol)) for j in range(len(masks)) for k in range(len(aaf_bins))]\n",
    "input: [f'{cwd}/{phenoFile:bn}_' + str(phenoCol[i]) +f'.{step_name.rsplit(\"_\",1)[0]}.snp_stats.gz' for i in range(len(phenoCol))]+[f'{cwd}/{phenoFile:bn}_' + str(phenoCol[i]) +f'.{step_name.rsplit(\"_\",1)[0]}.snp_counts.txt' for i in range(len(phenoCol))],group_by = lambda x: [x[i::len(phenoCol)] for i in range(len(phenoCol))], group_with='phenoCol'\n",
    "output: [f'{cwd}/{phenoFile:bn}_' + bins[n] + '.snp_stats.gz' for n in range(len(bins))]+[f'{cwd}/{phenoFile:bn}_' + bins[n] + '.snp_counts.txt' for n in range(len(bins))]\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '3h', mem = '64G', tags = f'{step_name}_{_input[0]:bn}'    \n",
    "python: container= container, expand = \"${ }\", stderr = f'{cwd}/{step_name}.stderr', stdout = f'{cwd}/{step_name}.stdout'\n",
    "    import gzip\n",
    "    import pandas as pd\n",
    "    data=pd.read_csv(${_input[0]:r}, compression='gzip', header=0, sep=r'\\s+', quotechar='\"', comment='#')\n",
    "    binlist=pd.unique(data.ALT)\n",
    "    \n",
    "    for bin in binlist:\n",
    "        # Separate regenie results into mask and MAF bins\n",
    "        data[data['ALT']==bin].to_csv(\"${_input[0]:nn}.\"+bin+'.snp_stats.gz', compression='gzip', sep='\\t', header = True, index = False)\n",
    "        \n",
    "    \n",
    "    count=pd.read_csv(${_input[1]:r}, header=None, sep=r'\\s+')\n",
    "    for bin in binlist:\n",
    "        count[count[0].str.contains(bin)].to_csv(\"${_input[0]:nn}.\"+bin+'.snp_counts.txt', sep='\\t', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf99aea0-6b8e-495d-8f82-37c2345877ae",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Separate the mask and MAF bins and remove the single variant genes\n",
    "[regenie_vc_5]\n",
    "# Top k genes to be annotated\n",
    "parameter: k = 10\n",
    "# P value limitation for annotation\n",
    "parameter: plim = 2.5E-6\n",
    "# A given list of gene for annotation\n",
    "parameter: genelist = \"\"\n",
    "# Select the annotations to be used in the mask file. format: mask# annotation type\n",
    "parameter: mask_file = path(\".\")\n",
    "# Select the upper MAF to generate masks\n",
    "parameter: aaf_bins = [0.001]\n",
    "import pandas as pd\n",
    "f = open(mask_file, \"r\")\n",
    "masks = [i.split(\" \")[0] for i in f.readlines()]\n",
    "bins=[str(phenoCol[i]) + f'.{step_name.rsplit(\"_\",1)[0]}.' + str(masks[j]) + \".\" + str(aaf_bins[k]) for i in range(len(phenoCol)) for j in range(len(masks)) for k in range(len(aaf_bins))]\n",
    "input: [f'{cwd}/{phenoFile:bn}_' + str(phenoCol[i]) + f'.{step_name.rsplit(\"_\",1)[0]}.snp_stats.gz' for i in range(len(phenoCol))]+[f'{cwd}/{phenoFile:bn}_' + str(phenoCol[i]) +f'.{step_name.rsplit(\"_\",1)[0]}.snp_counts.txt' for i in range(len(phenoCol))],group_by = lambda x: [x[i::len(phenoCol)] for i in range(len(phenoCol))], group_with='phenoCol'\n",
    "df=pd.read_csv(_input[0], compression='gzip', header=0, sep=r'\\s+', quotechar='\"', comment='#')\n",
    "vc=pd.unique(df['TEST'])\n",
    "output: [f'{cwd}/{phenoFile:bn}_' + bins[n] +'_'+ vc[k] +'.snp_stats.gz' for n in range(len(bins)) for k in range(len(vc))]\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '3h', mem = '64G', tags = f'{step_name}_{_input[0]:bn}'    \n",
    "python: container= container, expand = \"${ }\", stderr = f'{cwd}/{step_name}.stderr', stdout = f'{cwd}/{step_name}.stdout'\n",
    "    import gzip\n",
    "    import pandas as pd\n",
    "    data=pd.read_csv(${_input[0]:r}, compression='gzip', header=0, sep=r'\\s+', quotechar='\"', comment='#')\n",
    "    grouped = data.groupby(['TEST', 'ALT'])\n",
    "    # Iterate over groups and save each group to a separate file\n",
    "    for (test_value, alt_value), group in grouped:\n",
    "    #Sort the data in the summary stats based on position\n",
    "        group=group.sort_values(by=['POS'])\n",
    "    # Define the output file name based on TEST and ALLELE1 values\n",
    "        output_file_name = f\"${_input[0]:nn}.{alt_value}_{test_value}.snp_stats.gz\"\n",
    "    # Save the group to the output file\n",
    "        group.to_csv(output_file_name, compression='gzip', sep='\\t', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-volume",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Manhattan and QQ plots\n",
    "\n",
    "Before running the pipeline make sure you have installed the necessary packages. We use the `qqman` package from R: https://www.r-graph-gallery.com/101_Manhattan_plot.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-companion",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Manhattan and QQ plots using `qqman`\n",
    "[regenie_4]\n",
    "# Column name for BP\n",
    "parameter: bp = 'POS'\n",
    "# Column name for p-value\n",
    "parameter: pval = 'P'\n",
    "# Column name for SNP\n",
    "parameter: snp = 'SNP'\n",
    "# ylim set to 0 to use maximum -log10(p) in data\n",
    "parameter: ylim = 0\n",
    "sep = '\\n\\n---\\n'\n",
    "depends: phenoFile\n",
    "input: group_by = 2, group_with = 'phenoCol'\n",
    "output: manhattan = f'{_input[0]:nn}.manhattan.png',\n",
    "        qq = f'{_input[0]:nn}.qq.png',\n",
    "        analysis_summary = f'{_input[0]:nn}.analysis_summary.md'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '3h', mem = '64G', tags = f'{step_name}_{_output[0]:bn}'    \n",
    "bash: container= container, expand = \"${ }\"\n",
    "    echo '''---\n",
    "    theme: base-theme\n",
    "    style: |\n",
    "      img {\n",
    "        height: 80%;\n",
    "        display: block;\n",
    "        margin-left: auto;\n",
    "        margin-right: auto;\n",
    "      }\n",
    "    ---    \n",
    "    ''' > ${_output[2]}\n",
    "    \n",
    "R:  container= container , expand='${ }', stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    # some summary statistics for phenotype\n",
    "    pheno = read.table(${phenoFile:r}, header=T, sep = \"\")$${_phenoCol}\n",
    "    if (length(unique(pheno))>2) {\n",
    "      out = capture.output(summary(pheno))\n",
    "    } else {\n",
    "      out = as.data.frame(table(pheno))\n",
    "      rownames(out) = c('n_ctrl', 'n_case')\n",
    "      out = out[,2,drop=F]\n",
    "    }\n",
    "    write('# ${_phenoCol} result summary\\n## Phenotype summary:\\n```', ${_output[2]:r}, append = T)\n",
    "    write.table(out, ${_output[2]:r}, append = T)\n",
    "    write(\"```\", ${_output[2]:r}, append = T)\n",
    "\n",
    "R:  container= container, expand='${ }', stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    library('qqman')\n",
    "    data <- read.table(gzfile('${_input[0]}'), sep='\\t', header=T)\n",
    "    lambda <- median(qchisq(1-data$${pval},1), na.rm=TRUE)/qchisq(0.5,1)\n",
    "    ifelse((${ylim} == 0 && min(data$${pval}, na.rm=TRUE)!=0), ylim <- abs(floor(log10(min(data$${pval}, na.rm=TRUE)))), ylim <- abs(floor(log10(2.225074e-308))))\n",
    "    # Creating manhattan plot\n",
    "    png('${_output[0]}', width = 6, height = 4, unit='in', res=300)\n",
    "    manhattan_plot <- manhattan(data, chr='CHR', bp='${bp}', snp='${snp}', p='${pval}', main = 'Manhattan plot for ${_phenoCol} (${step_name.rsplit(\"_\",1)[0]})', ylim = c(0, ylim), cex = 0.6, \n",
    "    cex.axis = 0.9, col = c(\"blue4\", \"orange3\"), chrlabs = c(1:22))\n",
    "    dev.off()\n",
    "    # Creating qqplot\n",
    "    png('${_output[1]}', width = 5, height = 5, unit='in', res=300)\n",
    "    qq_plot <- qq(data$${pval}, main = 'QQ Plot for ${_phenoCol} (${step_name.rsplit(\"_\",1)[0]})', xlim = c(0, 8), ylim = c(0, ylim), pch = 18, col = \"blue4\", cex = 1.5, las = 1)\n",
    "    dev.off()\n",
    "    write('## p-value summary:', ${_output[2]:r}, append=T)\n",
    "    write(paste(\"Genomic inflation factor is\", round(lambda,3), \"for\", nrow(data), \"variants analyzed.${sep}\"), ${_output[2]:r}, append=T)\n",
    "     \n",
    "bash: expand = True\n",
    "  set -e\n",
    "  echo -e \"# QQ plot for {_phenoCol}\\n\" >> {_output[2]}\n",
    "  echo -e \"![]({_output[1]:bn}.png){sep}\" >> {_output[2]}\n",
    "  echo -e \"# Manhattan plot for {_phenoCol}\\n\" >> {_output[2]}\n",
    "  echo -e \"![]({_output[0]:bn}.png){sep}\" >> {_output[2]}\n",
    "  echo -e \"# Result files\\n\\`\\`\\`\" >> {_output[2]}\n",
    "  ls {_input[0]:nn}.* | grep -v 'stderr|stdout'>> {_output[2]}\n",
    "  echo -e \"\\`\\`\\`\" >> {_output[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d4405-e0dd-49c5-a5bf-0a5c223d6033",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Manhattan and QQ plots using `qqman`\n",
    "[regenie_vc_6]\n",
    "# Column name for BP\n",
    "parameter: bp = 'POS'\n",
    "# Column name for p-value\n",
    "parameter: pval = 'P'\n",
    "# Column name for genes\n",
    "parameter: snp = 'SNP'\n",
    "# ylim set to 0 to use maximum -log10(p) in data\n",
    "parameter: ylim = 0\n",
    "# Select the upper MAF to generate masks\n",
    "parameter: aaf_bins =[0.001]\n",
    "# The vc_tests performed\n",
    "parameter: vc_tests_reg =['ADD-SKAT','ADD-SKATO']\n",
    "# Select the annotations to be used in the mask file. format: mask# annotation_type\n",
    "parameter: mask_file = path(\".\")\n",
    "f = open(mask_file, \"r\")\n",
    "masks = [i.split(\" \")[0] for i in f.readlines()]\n",
    "bins=[str(phenoCol[i]) + f'.{step_name.rsplit(\"_\",1)[0]}.' + str(masks[j]) + \".\" + str(aaf_bins[k]) for i in range(len(phenoCol)) for j in range(len(masks)) for k in range(len(aaf_bins))]\n",
    "vc=[str(phenoCol[i]) + f'.{step_name.rsplit(\"_\",1)[0]}.' + str(masks[j]) + \".\" + str(aaf_bins[k]) + \"_\" + str(vc_tests_reg[l]) for i in range(len(phenoCol)) for j in range(len(masks)) for k in range(len(aaf_bins)) for l in range(len(vc_tests_reg))]\n",
    "print(vc)\n",
    "sep = '\\n\\n---\\n'\n",
    "depends: phenoFile\n",
    "input:[f'{cwd}/{phenoFile:bn}_' + bins[n] +'_'+ vc_tests_reg[k] +'.snp_stats.gz' for n in range(len(bins)) for k in range(len(vc_tests_reg))], group_by=1\n",
    "output: manhattan = f'{_input[0]:nn}.manhattan.png',\n",
    "        qq = f'{_input[0]:nn}.qq.png',\n",
    "        analysis_summary = f'{_input[0]:nn}.analysis_summary.md'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '3h', mem = '64G', tags = f'{step_name}_{_output[0]:bn}'   \n",
    "bash: container= container,  expand = \"${ }\"\n",
    "    echo '''---\n",
    "    theme: base-theme\n",
    "    style: |\n",
    "      img {\n",
    "        height: 80%;\n",
    "        display: block;\n",
    "        margin-left: auto;\n",
    "        margin-right: auto;\n",
    "      }\n",
    "    ---    \n",
    "    ''' > ${_output[2]}\n",
    "    \n",
    "R: container= container, expand='${ }', stderr = f'{cwd}/{step_name}.stderr', stdout = f'{cwd}/{step_name}.stdout'\n",
    "    # some summary statistics for phenotype\n",
    "    tmp=unlist(strsplit(${_input[0]:r},\"${cwd}/${phenoFile:bn}_\"))[2]\n",
    "    bins=unlist(strsplit(tmp,\".snp_stats.gz\"))[1]\n",
    "    phenoCol=unlist(strsplit(bins,\"\\\\.\"))[1]\n",
    "    pheno = read.table(${phenoFile:r}, header=T, sep = \"\")[${phenoCol}]\n",
    "    if (length(unique(pheno))>2) {\n",
    "      out = capture.output(summary(pheno))\n",
    "    } else {\n",
    "      out = as.data.frame(table(pheno))\n",
    "      rownames(out) = c('n_ctrl', 'n_case')\n",
    "      out = out[,2,drop=F]\n",
    "    }\n",
    "    write(paste0('# ',bins,' result summary\\n## Phenotype summary:\\n```'), ${_output[2]:r}, append = T)\n",
    "    write.table(out, ${_output[2]:r}, append = T)\n",
    "    write(\"```\", ${_output[2]:r}, append = T)\n",
    "\n",
    "R:  container= container, expand='${ }', stderr = f'{cwd}/{step_name}.stderr', stdout = f'{cwd}/{step_name}.stdout'\n",
    "    tmp=unlist(strsplit(${_input[0]:r},\"${cwd}/${phenoFile:bn}_\"))[2]\n",
    "    bins=unlist(strsplit(tmp,\".snp_stats.gz\"))[1]\n",
    "    library('qqman')\n",
    "    data <- read.table(gzfile('${_input[0]}'), sep='\\t', header=T)\n",
    "    lambda <- median(qchisq(1-data$${pval},1), na.rm=TRUE)/qchisq(0.5,1)\n",
    "    ifelse((${ylim} == 0 && min(data$${pval}, na.rm=TRUE)!=0), ylim <- abs(floor(log10(min(data$${pval}, na.rm=TRUE)))), ylim <- abs(floor(log10(2.225074e-308))))\n",
    "    # Creating manhattan plot\n",
    "    png('${_output[0]}', width = 6, height = 4, unit='in', res=300)\n",
    "    manhattan_plot <- manhattan(data, chr='CHR', bp='${bp}', snp='${snp}', p='${pval}', main = paste0('Manhattan plot for ',bins), ylim = c(0, ylim), cex = 0.6, \n",
    "    cex.axis = 0.9, col = c(\"blue4\", \"orange3\"),  xlim=c(0,max(data$POS)*1.2))  #, chrlabs = as.character(c(1:22))\n",
    "    dev.off()\n",
    "    # Creating qqplot\n",
    "    png('${_output[1]}', width = 5, height = 5, unit='in', res=300)\n",
    "    qq_plot <- qq(data$${pval}, main = paste0('QQ plot for ',bins), xlim = c(0, 8), ylim = c(0, ylim), pch = 18, col = \"blue4\", cex = 1.5, las = 1)\n",
    "    dev.off()\n",
    "    write('## p-value summary:', ${_output[2]:r}, append=T)\n",
    "    write(paste(\"Genomic inflation factor is\", round(lambda,3), \"for\", nrow(data), \"genes analyzed.${sep}\"), ${_output[2]:r}, append=T)\n",
    "    \n",
    "bash: container= container, expand = True\n",
    "  set -e\n",
    "  echo -e \"# QQ plot for {_input[0]:bnnn}\\n\" >> {_output[2]}\n",
    "  echo -e \"![]({_output[1]:bn}.png){sep}\" >> {_output[2]}\n",
    "  echo -e \"# Manhattan plot for {_input[0]:bnnn}\\n\" >> {_output[2]}\n",
    "  echo -e \"![]({_output[0]:bn}.png){sep}\" >> {_output[2]}\n",
    "  echo -e \"# Result files\\n\\`\\`\\`\" >> {_output[2]}\n",
    "  ls {_input[0]:nnn}.* | grep -vP 'stderr|stdout'>> {_output[2]}\n",
    "  echo -e \"\\`\\`\\`\" >> {_output[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-stomach",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Manhattan and QQ plots using `qqman`\n",
    "[regenie_burden_6]\n",
    "# Column name for BP\n",
    "parameter: bp = 'POS'\n",
    "# Column name for p-value\n",
    "parameter: pval = 'P'\n",
    "# Column name for genes\n",
    "parameter: snp = 'SNP'\n",
    "# ylim set to 0 to use maximum -log10(p) in data\n",
    "parameter: ylim = 0\n",
    "# Select the upper MAF to generate masks\n",
    "parameter: aaf_bins =[0.001]\n",
    "# Select the annotations to be used in the mask file. format: mask# annotation_type\n",
    "parameter: mask_file = path(\".\")\n",
    "f = open(mask_file, \"r\")\n",
    "masks = [i.split(\" \")[0] for i in f.readlines()]\n",
    "bins=[str(phenoCol[i]) + f'.{step_name.rsplit(\"_\",1)[0]}.' + str(masks[j]) + \".\" + str(aaf_bins[k]) for i in range(len(phenoCol)) for j in range(len(masks)) for k in range(len(aaf_bins))]\n",
    "sep = '\\n\\n---\\n'\n",
    "depends: phenoFile\n",
    "input: [f'{cwd}/{phenoFile:bn}_' + bins[n] + '.snp_stats.gz' for n in range(len(bins))], group_by=1\n",
    "output: manhattan = f'{_input[0]:nn}.manhattan.png',\n",
    "        qq = f'{_input[0]:nn}.qq.png',\n",
    "        analysis_summary = f'{_input[0]:nn}.analysis_summary.md'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '3h', mem = '64G', tags = f'{step_name}_{_output[0]:bn}'   \n",
    "bash: container= container,  expand = \"${ }\"\n",
    "    echo '''---\n",
    "    theme: base-theme\n",
    "    style: |\n",
    "      img {\n",
    "        height: 80%;\n",
    "        display: block;\n",
    "        margin-left: auto;\n",
    "        margin-right: auto;\n",
    "      }\n",
    "    ---    \n",
    "    ''' > ${_output[2]}\n",
    "    \n",
    "R: container= container, expand='${ }', stderr = f'{cwd}/{step_name}.stderr', stdout = f'{cwd}/{step_name}.stdout'\n",
    "    # some summary statistics for phenotype\n",
    "    tmp=unlist(strsplit(${_input[0]:r},\"${cwd}/${phenoFile:bn}_\"))[2]\n",
    "    bins=unlist(strsplit(tmp,\".snp_stats.gz\"))[1]\n",
    "    phenoCol=unlist(strsplit(bins,\"\\\\.\"))[1]\n",
    "    pheno = read.table(${phenoFile:r}, header=T, sep = \"\")[${phenoCol}]\n",
    "    if (length(unique(pheno))>2) {\n",
    "      out = capture.output(summary(pheno))\n",
    "    } else {\n",
    "      out = as.data.frame(table(pheno))\n",
    "      rownames(out) = c('n_ctrl', 'n_case')\n",
    "      out = out[,2,drop=F]\n",
    "    }\n",
    "    write(paste0('# ',bins,' result summary\\n## Phenotype summary:\\n```'), ${_output[2]:r}, append = T)\n",
    "    write.table(out, ${_output[2]:r}, append = T)\n",
    "    write(\"```\", ${_output[2]:r}, append = T)\n",
    "\n",
    "R:  container= container, expand='${ }', stderr = f'{cwd}/{step_name}.stderr', stdout = f'{cwd}/{step_name}.stdout'\n",
    "    tmp=unlist(strsplit(${_input[0]:r},\"${cwd}/${phenoFile:bn}_\"))[2]\n",
    "    bins=unlist(strsplit(tmp,\".snp_stats.gz\"))[1]\n",
    "    library('qqman')\n",
    "    data <- read.table(gzfile('${_input[0]}'), sep='\\t', header=T)\n",
    "    lambda <- median(qchisq(1-data$${pval},1), na.rm=TRUE)/qchisq(0.5,1)\n",
    "    ifelse((${ylim} == 0 && min(data$${pval}, na.rm=TRUE)!=0), ylim <- abs(floor(log10(min(data$${pval}, na.rm=TRUE)))), ylim <- abs(floor(log10(2.225074e-308))))\n",
    "    # Creating manhattan plot\n",
    "    png('${_output[0]}', width = 6, height = 4, unit='in', res=300)\n",
    "    manhattan_plot <- manhattan(data, chr='CHR', bp='${bp}', snp='${snp}', p='${pval}', main = paste0('Manhattan plot for ',bins), ylim = c(0, ylim), cex = 0.6, \n",
    "    cex.axis = 0.9, col = c(\"blue4\", \"orange3\"), xlim=c(0,max(data$POS)*1.2))  #, chrlabs = as.character(c(1:22))\n",
    "    dev.off()\n",
    "    # Creating qqplot\n",
    "    png('${_output[1]}', width = 5, height = 5, unit='in', res=300)\n",
    "    qq_plot <- qq(data$${pval}, main = paste0('QQ plot for ',bins), xlim = c(0, 8), ylim = c(0, ylim), pch = 18, col = \"blue4\", cex = 1.5, las = 1)\n",
    "    dev.off()\n",
    "    write('## p-value summary:', ${_output[2]:r}, append=T)\n",
    "    write(paste(\"Genomic inflation factor is\", round(lambda,3), \"for\", nrow(data), \"genes analyzed.${sep}\"), ${_output[2]:r}, append=T)\n",
    "    \n",
    "bash: container= container, expand = True\n",
    "  set -e\n",
    "  echo -e \"# QQ plot for {_input[0]:bnnn}\\n\" >> {_output[2]}\n",
    "  echo -e \"![]({_output[1]:bn}.png){sep}\" >> {_output[2]}\n",
    "  echo -e \"# Manhattan plot for {_input[0]:bnnn}\\n\" >> {_output[2]}\n",
    "  echo -e \"![]({_output[0]:bn}.png){sep}\" >> {_output[2]}\n",
    "  echo -e \"# Result files\\n\\`\\`\\`\" >> {_output[2]}\n",
    "  ls {_input[0]:nnn}.* | grep -vP 'stderr|stdout'>> {_output[2]}\n",
    "  echo -e \"\\`\\`\\`\" >> {_output[2]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.24.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
